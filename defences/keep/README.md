# Keep

Keep, also known as instruction defence or prompt defence, refers to techniques that focus on safeguarding the Large Language Model (LLM) by directly manipulating the system prompt or the developer controlled part of a user input into a prompt. This involves crafting prompts in ways that limit the potential for unintended or harmful outputs, such as by explicitly instructing the model to avoid generating certain types of content, adhere to specific guidelines, or stay within defined boundaries. There are a number of techniques for prompt defence - described below
