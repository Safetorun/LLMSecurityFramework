# Spotlighting

* Delimiting involves using special tokens to clearly mark the beginning and end of input text within the system prompt, signalling the model to avoid interpreting any instructions within these boundaries. For example, a system prompt for document summarisation could include "<<" and ">>" to enclose the input text and instruct the model to disregard any embedded instructions within those symbols.
* Datamarking extends the concept of delimiting by interleaving a special token throughout the entire input text, rather than just at the beginning and end. For example, all whitespace in an input document could be replaced with a special token like "^," and the system prompt would inform the model about this transformation and its purpose in distinguishing trusted instructions from potentially malicious ones.
* Encoding involves transforming the input text using an encoding algorithm like base64 or ROT13. The system prompt would then instruct the model to decode the input text before processing it while emphasising that instructions within the encoded text should be ignored. This approach leverages the LLM's ability to understand common encoding schemes while providing a more robust signal of the input text's provenance.
